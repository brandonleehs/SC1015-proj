{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d8316e",
   "metadata": {},
   "source": [
    "# SC1015 Mini-Project\n",
    "\n",
    "Group: 2, FCEE\n",
    "\n",
    "Lee Heng Sheng Brandon, U2322900C \\\n",
    "Alan Lee Leman, U2321753B \\\n",
    "Wee Zi Hao, U2323380H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a5723",
   "metadata": {},
   "source": [
    "### Final Attribute Information\n",
    "\n",
    "> 1. `age`: age in years (Numerical)\n",
    "2. `sex`: 0 = female; 1 = male (Categorical)\n",
    "3. `cp` changed to `chest_pain`: Chest pain type (4 values) (Categorical)\n",
    "4. `trestbps` changed to `blood_pressure`: Resting blood pressure (in mm Hg on admission to the hospital) (Numerical)\n",
    "5. `chol` changed to `cholesterol`: Serum cholesterol in mg/dl (serum cholestoral in mg/dl) (Numerical)\n",
    "6. `fbs` changed to `fasting_blood_sugar`: Fasting blood sugar > 120 mg/dl (1 = true; 0 = false) (Categorical)\n",
    "7. `restecg` changed to `resting_ecg_result`: Resting electrocardiographic results (values 0,1,2) (Categorical)\n",
    "8. `thalach` changed to `max_heart_rate`: Maximum heart rate achieved (in bpm) (Numerical)\n",
    "9. `exang` changed to `exercise_induced_angina`: Exercise induced angina (0 = no; 1 = yes) (Categorical)\n",
    "10. `oldpeak` changed to `st_depression`: ST depression induced by exercise relative to rest (Numerical)\n",
    "11. `new_st_depression`: The presence of ST depression induced by exercise relative to rest (0 = no; 1 = yes) (Categorical)\n",
    "12. `slope`: The slope of the peak exercise ST segment (0, 1, 2) (Categorical)\n",
    "13. `ca` changed to `num_affected_vessels`: Number of major vessels (0-3) colored by fluoroscopy (Categorical)\n",
    "14. `thal` changed to `defect_type`: 1 = normal; 2 = fixed defect; 3 = reversable defect (Categorical)\n",
    "15. `target` changed to `heart_disease`: 0 = no heart disease; 1 = heart disease (Categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1c143",
   "metadata": {},
   "source": [
    "### Essential Libraries\n",
    "\n",
    "Let us begin by importing the essential Python Libraries for Data Extraction and Cleaning.\n",
    "\n",
    "> NumPy : Library for Numeric Computations in Python \\\n",
    "Pandas : Library for Data Acquisition and Preparation \\\n",
    "Matplotlib : Low-level library for Data Visualization \\\n",
    "Seaborn : Higher-level library for Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5f6b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd44185",
   "metadata": {},
   "source": [
    "### Import the Dataset\n",
    "\n",
    "We will be importing our clean_data.csv dataset that we previously saved.\\\n",
    "Dataset is a cleaned version of [Heart Disease](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset). By David Lapp. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd16c069",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (1000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>resting_ecg_result</th>\n",
       "      <th>max_heart_rate</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>st_depression</th>\n",
       "      <th>new_st_depression</th>\n",
       "      <th>slope</th>\n",
       "      <th>num_affected_vessels</th>\n",
       "      <th>defect_type</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  chest_pain  blood_pressure  cholesterol  fasting_blood_sugar  \\\n",
       "0     52    1           0             125          212                    0   \n",
       "1     53    1           0             140          203                    1   \n",
       "2     70    1           0             145          174                    0   \n",
       "3     61    1           0             148          203                    0   \n",
       "4     62    0           0             138          294                    1   \n",
       "..   ...  ...         ...             ...          ...                  ...   \n",
       "995   59    1           1             140          221                    0   \n",
       "996   60    1           0             125          258                    0   \n",
       "997   47    1           0             110          275                    0   \n",
       "998   50    0           0             110          254                    0   \n",
       "999   54    1           0             120          188                    0   \n",
       "\n",
       "     resting_ecg_result  max_heart_rate  exercise_induced_angina  \\\n",
       "0                     1             168                        0   \n",
       "1                     0             155                        1   \n",
       "2                     1             125                        1   \n",
       "3                     1             161                        0   \n",
       "4                     1             106                        0   \n",
       "..                  ...             ...                      ...   \n",
       "995                   1             164                        1   \n",
       "996                   0             141                        1   \n",
       "997                   0             118                        1   \n",
       "998                   0             159                        0   \n",
       "999                   1             113                        0   \n",
       "\n",
       "     st_depression  new_st_depression  slope  num_affected_vessels  \\\n",
       "0              1.0                  1      2                     2   \n",
       "1              3.1                  1      0                     0   \n",
       "2              2.6                  1      0                     0   \n",
       "3              0.0                  0      2                     1   \n",
       "4              1.9                  1      1                     3   \n",
       "..             ...                ...    ...                   ...   \n",
       "995            0.0                  0      2                     0   \n",
       "996            2.8                  1      1                     1   \n",
       "997            1.0                  1      1                     1   \n",
       "998            0.0                  0      2                     0   \n",
       "999            1.4                  1      1                     1   \n",
       "\n",
       "     defect_type  heart_disease  \n",
       "0              3              0  \n",
       "1              3              0  \n",
       "2              3              0  \n",
       "3              3              0  \n",
       "4              2              0  \n",
       "..           ...            ...  \n",
       "995            2              1  \n",
       "996            3              0  \n",
       "997            2              0  \n",
       "998            2              1  \n",
       "999            3              0  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing our dataset\n",
    "clean_data = pd.read_csv(\"datasets\\clean_data.csv\")\n",
    "\n",
    "print(\"Data dimensions:\", clean_data.shape)\n",
    "\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e08f802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of numerical and categorical variables\n",
    "cat_var = [\"sex\", \"chest_pain\", \"fasting_blood_sugar\", \"resting_ecg_result\", \"exercise_induced_angina\", \"new_st_depression\", \n",
    "           \"slope\", \"num_affected_vessels\", \"defect_type\", \"heart_disease\"]\n",
    "num_var = [var for var in clean_data.columns if var not in cat_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f72686",
   "metadata": {},
   "source": [
    "## Assumptions of Logistic Regression\n",
    "\n",
    "Because logistic regression does not assume normality, the model will not be affected by skew. Thus, we should not be removing outliers from our data.\n",
    "\n",
    "Rather, logistic regression assumes the following:\n",
    "\n",
    "1. Independence of Observations (which we shall assume)\n",
    "2. Absence of Multicollinearity (independent variables should not be highly correlated with any other variable in the model)\n",
    "3. Linearity of Logit (there is a linear relationship between the logit of the dependent variable and the (continuous) independent variable)\n",
    "\n",
    "We can use these assumptions to determine the relevant independent variables for our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7c778",
   "metadata": {},
   "source": [
    "### Absence of Multicollinearity\n",
    "\n",
    "We can test for this with VIF (Variance Inflation Factor). The formula is given as:\n",
    "\n",
    "$VIF_i = \\frac{1}{1 - R^2}$\n",
    "\n",
    "Generally, a VIF above 5 indicates a high multicollinearity and we should avoid using these independent variables in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d104e4d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['target'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29420\\2109975869.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get independent variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mindependent_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# variance_inflation_factor expects the presence of a constant in the matrix of explanatory variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4955\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4956\u001b[0m         \"\"\"\n\u001b[1;32m-> 4957\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4958\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4959\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4267\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4311\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4312\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6660\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6661\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6662\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6663\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['target'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Get independent variables\n",
    "independent_vars = clean_data.drop(\"target\", axis = 1)\n",
    "\n",
    "# variance_inflation_factor expects the presence of a constant in the matrix of explanatory variables\n",
    "# We can add a constant column using add_constant from statsmodels\n",
    "independent_vars = add_constant(independent_vars)\n",
    "\n",
    "VIF_df = pd.DataFrame(independent_vars.columns).rename({0 : \"VARIABLES\"}, axis = 1) # rename variable column\n",
    "\n",
    "VIF_df[\"VIF\"] = [vif(independent_vars, i) for i in range(len(independent_vars.columns))]\n",
    "\n",
    "VIF_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e45d32",
   "metadata": {},
   "source": [
    "It appears that all our variables have a VIF below 5, and we do not need to drop any of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995dce2",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "Since Logistic Regression is a linear model, we will need to convert categorical variables into a set of binary (dummy) variables before fitting them in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the encoder from sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# One-Hot Encoding of categorical predictors\n",
    "cat_pred = clean_data[cat_var].drop(\"target\", axis = 1)\n",
    "ohe.fit(cat_pred)\n",
    "\n",
    "cat_pred_ohe = pd.DataFrame(ohe.transform(cat_pred).toarray(), \n",
    "             columns = ohe.get_feature_names_out(cat_pred.columns))\n",
    "\n",
    "# Check the encoded variables\n",
    "cat_pred_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1403936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with the numeric variables\n",
    "clean_data_ohe = pd.concat([clean_data[num_var], cat_pred_ohe, clean_data[\"target\"]], axis = 1)\n",
    "\n",
    "print(\"Dimensions:\", clean_data_ohe.shape)\n",
    "\n",
    "# Check the final DataFrame\n",
    "clean_data_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into predictors and response\n",
    "X = clean_data_ohe.drop([\"target\"], axis = 1)\n",
    "y = clean_data_ohe[\"target\"]\n",
    "\n",
    "# Split the dataset into train and test (80:20 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter = 300) # default 100 max iterations leads to convergence\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classes:\", logreg.classes_)\n",
    "print(\"Intercept:\", logreg.intercept_)\n",
    "print(\"Coefficients:\", [i.round(4) for i in logreg.coef_[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330bb54a",
   "metadata": {},
   "source": [
    "### Goodness of Fit of Model\n",
    "\n",
    "Let us check its classification accuracy and its confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d36e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict target with model\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", logreg.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", logreg.score(X_test, y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb47de2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "axes[0].set_title(\"Train\")\n",
    "axes[1].set_title(\"Test\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to print rate metrics\n",
    "def printMetrics(true, pred): \n",
    "    FP = confusion_matrix(true, pred)[0][1]\n",
    "    FN = confusion_matrix(true, pred)[1][0]\n",
    "    TP = confusion_matrix(true, pred)[1][1]\n",
    "    TN = confusion_matrix(true, pred)[0][0]\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FNR = FN / (FN + TP)\n",
    "    print(\"TPR:\\t\", TPR)\n",
    "    print(\"FPR:\\t\", FPR)\n",
    "    print(\"TNR:\\t\", TNR)\n",
    "    print(\"FNR:\\t\", FNR)\n",
    "    print()\n",
    "\n",
    "print(\"TRAIN SET:\")\n",
    "printMetrics(y_train, y_train_pred)\n",
    "print(\"TEST SET:\")\n",
    "printMetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6702565",
   "metadata": {},
   "source": [
    "### Linearity of Logit\n",
    "\n",
    "We shall check for this by plotting the logit of the dependent variable `target` against the independent variables in a scatterplot. We can also check for linearity with pearson's correlation. The formula for logit is given as: \n",
    "\n",
    "$Logit(p) = \\log (\\frac{p}{1 - p})$\n",
    "\n",
    "where $p$ is odds of success and $1 - p$ is the odds of failure. We can get the estimated probabilities from our model with `predict_proba()`. Let us first check the linearity on the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_arr = logreg.predict_proba(X_train)\n",
    "\n",
    "proba_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847292e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Make the logit function\n",
    "logit = lambda x : math.log(x[1] / x[0])\n",
    "\n",
    "target = clean_data_ohe[\"target\"]\n",
    "clean_data_ohe = clean_data_ohe.drop([\"target\"], axis = 1)\n",
    "\n",
    "# Get the estimated probabilities\n",
    "proba_arr = logreg.predict_proba(clean_data_ohe)\n",
    "\n",
    "# Apply the logit function across all probability values\n",
    "logit_arr = np.array(list(map(logit, proba_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9137b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clean_data_ohe = pd.concat([clean_data_ohe, pd.DataFrame(logit_arr), target], axis = 1).rename({0 : \"logit\"}, axis = 1)\n",
    "\n",
    "clean_data_ohe[\"logit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7b462",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(len(num_var), 1, figsize = (24, 12))\n",
    "\n",
    "for i, var in enumerate(num_var):\n",
    "    sb.scatterplot(data = clean_data_ohe, x = var, y = \"logit\", ax = axes[i]).set(xlabel = var)\n",
    "    print(f\"{var} correlation:\", clean_data_ohe[var].corr(clean_data_ohe[\"logit\"]))\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "# Ok, something probably went wrong here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a0eaf",
   "metadata": {},
   "source": [
    "### Check for Relevant Variables via Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640c5d9",
   "metadata": {},
   "source": [
    "### Dimensionality Issue of One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d567c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
